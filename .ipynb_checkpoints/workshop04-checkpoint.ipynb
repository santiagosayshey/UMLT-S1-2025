{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 4\n",
    "\n",
    "Starter code for workshop 4. You should have seen most of it before, but make sure you understand what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# To plot even prettier figures\n",
    "import seaborn as sn\n",
    "\n",
    "# General data handling (pure numerics are better in numpy)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the numerical data is\n",
    "xarray = data.data\n",
    "yarray = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features names are: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Label names are: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# This is where the names of features and targets are\n",
    "print(f'Features names are: {data.feature_names}')\n",
    "print(f'Label names are: {data.target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recommend inverting the labels so that malignant (the worse disease) = 1 (i.e. positive)\n",
    "yarray = 1 - yarray\n",
    "# Don't forget to switch the label names too (if you are going to use them anywhere)\n",
    "# Though it is good practice to switch them here anyway, as future modifications to the code then won't get confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you could put it all into a pandas dataframe (useful for some investigations)\n",
    "fullarray = np.concatenate((xarray,np.reshape(yarray,(-1,1))),axis=1)\n",
    "df = pd.DataFrame(fullarray, columns = list(data.feature_names) + ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into separate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(364, 30), (364,), (114, 30), (114,), (91, 30), (91,)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bigtrain_set,test_set = train_test_split(df,test_size=0.2, random_state = 20)\n",
    "train_set, val_set = train_test_split(bigtrain_set, test_size=0.2, random_state=20)\n",
    "\n",
    "X_train = train_set.iloc[:,:-1]\n",
    "y_train = train_set.iloc[:,-1]\n",
    "X_test = test_set.iloc[:,:-1]\n",
    "y_test = test_set.iloc[:,-1]\n",
    "X_val = val_set.iloc[:,:-1]\n",
    "y_val = val_set.iloc[:,-1]\n",
    "print([X_train.shape,y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    # Step 1: Handle missing values (if any)\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    \n",
    "    # Step 2: Standardize features\n",
    "    # This is important because the features are on different scales\n",
    "    # (mean radius vs mean texture vs mean area have very different ranges)\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Apply the pipeline to each split individually (so the test data doesn't influence training data)\n",
    "X_train_processed = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_val_processed = preprocessing_pipeline.transform(X_val)\n",
    "X_test_processed = preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'loss' parameter of SGDClassifier must be a str among {'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'log_loss', 'squared_error', 'squared_hinge', 'perceptron', 'modified_huber', 'hinge'}. Got 'log' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m sgd_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# First, include all preprocessing steps\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessing_pipeline),\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Then add the SGD classifier\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, SGDClassifier(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model on the training data\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m sgd_pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get binary predictions (0 or 1)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m sgd_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1466\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1462\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1463\u001b[0m )\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    669\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    670\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'log_loss', 'squared_error', 'squared_hinge', 'perceptron', 'modified_huber', 'hinge'}. Got 'log' instead."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a pipeline that includes preprocessing and SGD classifier\n",
    "sgd_pipeline = Pipeline([\n",
    "    # First, include all preprocessing steps\n",
    "    ('preprocessor', preprocessing_pipeline),\n",
    "    # Then add the SGD classifier with the correct parameter\n",
    "    ('classifier', SGDClassifier(loss='log_loss', random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model on the training data\n",
    "sgd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get binary predictions (0 or 1)\n",
    "y_val_pred = sgd_pipeline.predict(X_val)\n",
    "\n",
    "# Get probability predictions (chance of being class 1)\n",
    "# The second column [[:,1]] gives the probability of the positive class (1)\n",
    "y_val_prob = sgd_pipeline.predict_proba(X_val)[:,1]\n",
    "\n",
    "print(\"First 10 binary predictions:\", y_val_pred[:10])\n",
    "print(\"First 10 probability predictions:\", y_val_prob[:10])\n",
    "\n",
    "# Create a plot to visualize predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Sort by actual values and then by predicted probabilities for better visualization\n",
    "sort_idx = np.lexsort((y_val_prob, y_val))\n",
    "sorted_y_val = y_val.values[sort_idx]\n",
    "sorted_y_val_pred = y_val_pred[sort_idx]\n",
    "sorted_y_val_prob = y_val_prob[sort_idx]\n",
    "\n",
    "# Plot actual values\n",
    "plt.scatter(range(len(sorted_y_val)), sorted_y_val, c='blue', label='Actual', alpha=0.5, s=100)\n",
    "\n",
    "# Plot predicted values\n",
    "plt.scatter(range(len(sorted_y_val_pred)), sorted_y_val_pred, c='red', marker='x', label='Predicted', alpha=0.5, s=100)\n",
    "\n",
    "# Highlight incorrect predictions\n",
    "incorrect = sorted_y_val != sorted_y_val_pred\n",
    "plt.scatter(np.where(incorrect)[0], sorted_y_val_pred[incorrect], c='green', marker='o', s=200, facecolors='none', label='Incorrect')\n",
    "\n",
    "plt.yticks([0, 1], ['Benign', 'Malignant'])\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Actual vs Predicted Classes')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Also create a plot of the probability predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(sorted_y_val_prob)), sorted_y_val_prob, 'o-', alpha=0.6)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Decision Threshold (0.5)')\n",
    "plt.scatter(np.where(incorrect)[0], sorted_y_val_prob[incorrect], c='green', s=100, label='Incorrect Predictions')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted Probability of Malignant')\n",
    "plt.title('Predicted Probabilities (sorted)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Display the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks([0.5, 1.5], ['Benign (0)', 'Malignant (1)'])\n",
    "plt.yticks([0.5, 1.5], ['Benign (0)', 'Malignant (1)'])\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Normalized Confusion Matrix (rows sum to 1.0)')\n",
    "plt.xticks([0.5, 1.5], ['Benign (0)', 'Malignant (1)'])\n",
    "plt.yticks([0.5, 1.5], ['Benign (0)', 'Malignant (1)'])\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {2 * (precision * recall) / (precision + recall):.4f}\")\n",
    "\n",
    "# Calculate ROC curve using binary predictions\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "\n",
    "# Calculate Area Under the Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Binary Predictions')\n",
    "plt.legend(loc=\"lower right\")\n",
    "print(f\"Number of distinct points in ROC curve using binary predictions: {len(fpr)}\")\n",
    "print(f\"Thresholds: {thresholds}\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curve using probability predictions\n",
    "fpr_prob, tpr_prob, thresholds_prob = roc_curve(y_val, y_val_prob)\n",
    "\n",
    "# Calculate Area Under the Curve (AUC)\n",
    "roc_auc_prob = auc(fpr_prob, tpr_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_prob, tpr_prob, color='blue', lw=2, label=f'ROC curve (area = {roc_auc_prob:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Probability Predictions')\n",
    "plt.legend(loc=\"lower right\")\n",
    "print(f\"Number of distinct points in ROC curve using probability predictions: {len(fpr_prob)}\")\n",
    "plt.show()\n",
    "\n",
    "# Let's look at wrong predictions and their probabilities\n",
    "wrong_idx = np.where(y_val != y_val_pred)[0]\n",
    "wrong_probs = y_val_prob[wrong_idx]\n",
    "wrong_true = y_val.values[wrong_idx]\n",
    "wrong_pred = y_val_pred[wrong_idx]\n",
    "\n",
    "print(\"\\nWrong predictions:\")\n",
    "for i, idx in enumerate(wrong_idx):\n",
    "    print(f\"Sample {idx}: True={wrong_true[i]}, Pred={wrong_pred[i]}, Prob={wrong_probs[i]:.4f}\")\n",
    "\n",
    "# Find closest thresholds to the wrong prediction probabilities\n",
    "for wrong_prob in wrong_probs:\n",
    "    closest_idx = np.argmin(np.abs(thresholds_prob - wrong_prob))\n",
    "    print(f\"For wrong prediction with prob {wrong_prob:.4f}, closest threshold: {thresholds_prob[closest_idx]:.4f}\")\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_val, y_val_prob)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve, precision_curve, color='blue', lw=2)\n",
    "plt.axhline(y=sum(y_val)/len(y_val), color='red', linestyle='--', label=f'Baseline (class distribution: {sum(y_val)/len(y_val):.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Look at different thresholds and their effect on precision and recall\n",
    "threshold_examples = [0.3, 0.5, 0.7, 0.9]\n",
    "results = []\n",
    "\n",
    "for threshold in threshold_examples:\n",
    "    # Convert probabilities to binary predictions based on threshold\n",
    "    y_pred_custom = (y_val_prob >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_val, y_pred_custom)\n",
    "    prec = precision_score(y_val, y_pred_custom)\n",
    "    rec = recall_score(y_val, y_pred_custom)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Display results as a dataframe\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
